# import os
# import json
# import time
# import pandas as pd
# import glob
# import requests

# CACHE_FILE = "audio_cache.json"
# PARENT_FOLDER = "data/data-top50"
# BASE_URL = "https://api.reccobeats.com/v1"

# # ========== CACHE ==========
# def load_cache():
#     if os.path.exists(CACHE_FILE):
#         try:
#             with open(CACHE_FILE, "r", encoding="utf-8") as f:
#                 return json.load(f)
#         except json.JSONDecodeError:
#             print("‚ö†Ô∏è Cache l·ªói, reset cache")
#             return {}
#     return {}

# def save_cache(cache):
#     with open(CACHE_FILE, "w", encoding="utf-8") as f:
#         json.dump(cache, f, indent=2, ensure_ascii=False)

# track_cache = load_cache()

# # ========== RECCOBEATS API (batch 20 + retry) ==========
# def get_audio_features_batch(track_ids, retries=3):
#     """L·∫•y audio features cho t·ªëi ƒëa 20 track_id, c√≥ retry n·∫øu b·ªã 429"""
#     uncached = [tid for tid in track_ids if tid and tid not in track_cache]
#     if not uncached:
#         return {tid: track_cache.get(tid) for tid in track_ids if tid}

#     ids_str = ",".join(uncached)
#     url = f"{BASE_URL}/audio-features?ids={ids_str}"

#     for attempt in range(retries):
#         resp = requests.get(url)
#         if resp.status_code == 200:
#             data = resp.json()
#             features_list = data.get("content", [])
#             for feat in features_list:
#                 tid = feat.get("href", "").split("/")[-1]
#                 if tid:
#                     clean_feat = {k: v for k, v in feat.items() if k != "id"}
#                     track_cache[tid] = clean_feat
#             save_cache(track_cache)
#             break
#         elif resp.status_code == 429:
#             wait_time = 5 * (attempt + 1)
#             print(f"‚è≥ Rate limited (429), ƒë·ª£i {wait_time}s r·ªìi th·ª≠ l·∫°i...")
#             time.sleep(wait_time)
#         elif resp.status_code in [500, 502, 503]:
#             wait_time = 5 * (attempt + 1)
#             print(f"‚ö†Ô∏è Server error {resp.status_code}, ƒë·ª£i {wait_time}s r·ªìi th·ª≠ l·∫°i...")
#             time.sleep(wait_time)
#         else:
#             print(f"‚ùå Error {resp.status_code} for batch {uncached[:3]}...")
#             break


#     return {tid: track_cache.get(tid) for tid in track_ids if tid}

# # ========== MAIN ==========
# def process_all_csv():
#     csv_files = glob.glob(f"{PARENT_FOLDER}/**/*-with-meta.csv", recursive=True)
#     print("üìÇ T·ªïng s·ªë file c·∫ßn x·ª≠ l√Ω:", len(csv_files))

#     for csv_file in csv_files:
#         print(f"\n‚û°Ô∏è ƒêang x·ª≠ l√Ω {csv_file}")
#         df = pd.read_csv(csv_file)

#         features_cols = [
#             "href", "acousticness", "danceability", "energy",
#             "instrumentalness", "key", "liveness", "loudness",
#             "mode", "speechiness", "tempo", "valence"
#         ]

#         results_data = {col: [] for col in ["track_id"] + features_cols}

#         track_ids = df["track_id"].dropna().astype(str).tolist()
#         for i in range(0, len(track_ids), 20):
#             batch_ids = track_ids[i:i+20]
#             results = get_audio_features_batch(batch_ids)

#             for tid in batch_ids:
#                 feat = results.get(tid)
#                 if feat:
#                     results_data["track_id"].append(tid)
#                     for col in features_cols:
#                         results_data[col].append(feat.get(col))
#                 # N·∫øu kh√¥ng c√≥ feat ‚Üí b·ªè qua (kh√¥ng ghi d√≤ng None)

#             print(f"‚úÖ Batch {i//20+1} x·ª≠ l√Ω xong ({len(batch_ids)} tracks)")

#         # T·∫°o DataFrame m·ªõi ch·ªâ c√≥ track_id + audio features
#         new_df = pd.DataFrame(results_data)
#         out_file = csv_file.replace("-with-meta.csv", "-with-audio.csv")
#         new_df.to_csv(out_file, index=False)
#         print(f"üíæ ƒê√£ l∆∞u {out_file} ({len(new_df)} d√≤ng)")

# if __name__ == "__main__":
#     process_all_csv()















import os
import json
import time
import pandas as pd
import glob
import requests

CACHE_FILE = "audio_cache.json"
PARENT_FOLDER = "data/data-top50"
BASE_URL = "https://api.reccobeats.com/v1"

# ================= CACHE =================
def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            print("‚ö†Ô∏è Cache l·ªói, reset cache")
            return {}
    return {}

def save_cache(cache):
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, indent=2, ensure_ascii=False)

track_cache = load_cache()

# ================= API CALL =================
def get_audio_features_batch(track_ids, retries=3):
    """
    L·∫•y audio features cho t·ªëi ƒëa 20 track_id t·ª´ ReccoBeats API.
    C√≥ retry khi g·∫∑p l·ªói 429 (rate limit) ho·∫∑c 500/502/503 (server error).
    """
    uncached = [tid for tid in track_ids if tid and tid not in track_cache]
    if not uncached:
        return {tid: track_cache.get(tid) for tid in track_ids if tid}

    ids_str = ",".join(uncached)
    url = f"{BASE_URL}/audio-features?ids={ids_str}"

    for attempt in range(retries):
        resp = requests.get(url)
        if resp.status_code == 200:
            data = resp.json()
            features_list = data.get("content", [])
            for feat in features_list:
                tid = feat.get("href", "").split("/")[-1]
                if tid:
                    # b·ªè id n·ªôi b·ªô, gi·ªØ l·∫°i c√°c field kh√°c
                    clean_feat = {k: v for k, v in feat.items() if k != "id"}
                    track_cache[tid] = clean_feat
            save_cache(track_cache)
            break
        elif resp.status_code == 429:
            wait_time = 5 * (attempt + 1)
            print(f"‚è≥ Rate limited (429), ƒë·ª£i {wait_time}s r·ªìi th·ª≠ l·∫°i...")
            time.sleep(wait_time)
        elif resp.status_code in [500, 502, 503]:
            wait_time = 5 * (attempt + 1)
            print(f"‚ö†Ô∏è Server error {resp.status_code}, ƒë·ª£i {wait_time}s r·ªìi th·ª≠ l·∫°i...")
            time.sleep(wait_time)
        else:
            print(f"‚ùå Error {resp.status_code} for batch {uncached[:3]}...")
            break
    else:
    # ch·ªâ ch·∫°y n·∫øu v√≤ng for k·∫øt th√∫c m√† kh√¥ng break (t·ª©c l√† th·∫•t b·∫°i sau 3 l·∫ßn)
        print(f"üö® Batch {uncached[:3]}... th·∫•t b·∫°i sau {retries} l·∫ßn th·ª≠, ghi None")

    return {tid: track_cache.get(tid) for tid in track_ids if tid}

# ================= MAIN =================
def process_all_csv():
    csv_files = glob.glob(f"{PARENT_FOLDER}/**/*-with-meta.csv", recursive=True)
    print("üìÇ T·ªïng s·ªë file c·∫ßn x·ª≠ l√Ω:", len(csv_files))

    for csv_file in csv_files:
        print(f"\n‚û°Ô∏è ƒêang x·ª≠ l√Ω {csv_file}")
        df = pd.read_csv(csv_file)

        features_cols = [
            "href", "acousticness", "danceability", "energy",
            "instrumentalness", "key", "liveness", "loudness",
            "mode", "speechiness", "tempo", "valence"
        ]

        results_data = {col: [] for col in ["track_id"] + features_cols}

        # b·ªè null/r·ªóng track_id
        track_ids = df["track_id"].dropna().astype(str).tolist()
        track_ids = [tid for tid in track_ids if tid.strip() != ""]

        for i in range(0, len(track_ids), 20):
            batch_ids = track_ids[i:i+20]
            results = get_audio_features_batch(batch_ids)

            for tid in batch_ids:
                feat = results.get(tid)
                results_data["track_id"].append(tid)
                if feat:
                    for col in features_cols:
                        results_data[col].append(feat.get(col))
                else:
                    # gi·ªØ d√≤ng nh∆∞ng ƒëi·ªÅn None cho audio features
                    for col in features_cols:
                        results_data[col].append(None)

            print(f"‚úÖ Batch {i//20+1} x·ª≠ l√Ω xong ({len(batch_ids)} tracks)")

        # T·∫°o DataFrame m·ªõi ch·ªâ c√≥ track_id + audio features
        new_df = pd.DataFrame(results_data)
        out_file = csv_file.replace("-with-meta.csv", "-with-audio.csv")
        new_df.to_csv(out_file, index=False)
        print(f"üíæ ƒê√£ l∆∞u {out_file} ({len(new_df)} d√≤ng)")

if __name__ == "__main__":
    process_all_csv()

